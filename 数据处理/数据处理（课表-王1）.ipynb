{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fd44b96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T16:31:58.945847600Z",
     "start_time": "2023-07-13T16:31:58.890847400Z"
    }
   },
   "outputs": [],
   "source": [
    "#导入需要的包\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime, timedelta\n",
    "from chinese_calendar import is_holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d952bbec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T17:07:18.211068600Z",
     "start_time": "2023-07-04T17:07:18.201607600Z"
    }
   },
   "outputs": [],
   "source": [
    "#从文件夹中读取csv格式文件并将其转换为DataFrame\n",
    "def load_data(file_path, file_name):\n",
    "\t'''\n",
    "    file_path : 文件路径名，即Data或temp\n",
    "\n",
    "    file_name : 文件名，如：lai.csv\n",
    "    '''\n",
    "\tdf = pd.read_csv(\"../\" + file_path + \"/\" + file_name, encoding='gbk')\n",
    "\tcolumns = df.columns\n",
    "\tdf.fillna(df.mean(numeric_only=True), inplace=True)\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af9e4102",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T17:07:18.236989500Z",
     "start_time": "2023-07-04T17:07:18.213067700Z"
    }
   },
   "outputs": [],
   "source": [
    "#截取样本并根据列值去除异常样本\n",
    "def cut_data(df, column_name, cut_index, abnormal_list):\n",
    "\t'''\n",
    "    df : DataFrame格式数据\n",
    "\n",
    "    column_name : 将要作为截取依据的列，如：要去除非用餐样本，可以将“商户名称”作为依据\n",
    "\n",
    "    cut_index : 截取的下标，如：在lai.csv中一区数据从591开始\n",
    "\n",
    "    abnormal_list : 异常样本列表\n",
    "    '''\n",
    "\tcut_df = df[:cut_index]\n",
    "\n",
    "\t# 创建一个空的 DataFrame 用于存储筛选后的数据\n",
    "\tfiltered_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "\tfor index, row in cut_df.iterrows():\n",
    "\t\tif row[column_name] in abnormal_list:\n",
    "\t\t\tcontinue\n",
    "\t\telse:\n",
    "\t\t\t# 将不满足条件的行添加到 filtered_df\n",
    "\t\t\tfiltered_df = pd.concat([filtered_df, row.to_frame().T], ignore_index=True)\n",
    "\treturn filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8503b579",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T17:07:18.242985700Z",
     "start_time": "2023-07-04T17:07:18.232985200Z"
    }
   },
   "outputs": [],
   "source": [
    "#将前后间隔不超过30分钟且刷卡地点相同的数据合并\n",
    "def merge_data(df):\n",
    "\t'''\n",
    "    df : DataFrame格式数据\n",
    "    '''\n",
    "\t#创建一个空的DataFrame或列表来存储处理后的数据。\n",
    "\tprocessed_data = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "\tdf['时间'] = df['交易日期'] + ' ' + df['交易时间']\n",
    "\tdf['时间'] = pd.to_datetime(df['时间'], format='%Y/%m/%d %H:%M')\n",
    "\n",
    "\tprev_row = None\n",
    "\n",
    "\tfor index, row in df.iterrows():\n",
    "\t\tif prev_row is None:\n",
    "\t\t\tprev_row = row\n",
    "\t\telse:\n",
    "\t\t\ttime_diff = prev_row['时间'] - row['时间']\n",
    "\t\t\tif (time_diff <= pd.Timedelta(minutes=30)) and (row['商户名称'] == prev_row['商户名称']) and (\n",
    "\t\t\t\t\trow['学工号'] == prev_row['学工号']):\n",
    "\t\t\t\tprev_row['交易额'] += row['交易额']\n",
    "\t\t\telse:\n",
    "\t\t\t\tprocessed_data = pd.concat([processed_data, prev_row.to_frame().T], ignore_index=True)\n",
    "\t\t\t\tprev_row = row\n",
    "\n",
    "\t# 处理最后一行数据\n",
    "\tprocessed_data = pd.concat([processed_data, prev_row.to_frame().T], ignore_index=True)\n",
    "\treturn processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07c954b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T17:07:18.257753600Z",
     "start_time": "2023-07-04T17:07:18.244986200Z"
    }
   },
   "outputs": [],
   "source": [
    "#添加特征列，列值为时间的小时整点，用于与天气数据连接\n",
    "def time2int(df):\n",
    "\t'''\n",
    "    df : DataFrame格式数据\n",
    "    '''\n",
    "\t# 将交易时间数据保存在一个名为\"trade_times\"的列表中\n",
    "\ttrade_times = df['交易时间']\n",
    "\n",
    "\tprocessed_times = []\n",
    "\n",
    "\tfor time_str in trade_times:\n",
    "\t\t# 将时间字符串转换为datetime对象\n",
    "\t\tdt = datetime.strptime(time_str, \"%H:%M\")\n",
    "\t\t# 如果分钟大于等于30，则小时进一位，并将分钟置为0\n",
    "\t\tif dt.minute >= 30:\n",
    "\t\t\tdt = dt.replace(hour=dt.hour + 1, minute=0)\n",
    "\t\telse:\n",
    "\t\t\tdt = dt.replace(minute=0)\n",
    "\t\t# 将处理后的时间添加到列表中\n",
    "\t\tprocessed_times.append(dt.strftime(\"%H:%M\"))\n",
    "\n",
    "\tdf['时间'] = processed_times\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54b458cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T17:07:18.306050200Z",
     "start_time": "2023-07-04T17:07:18.259753100Z"
    }
   },
   "outputs": [],
   "source": [
    "#将星期特征转换为数值，如 ：星期二 -> 2\n",
    "def week2num(df, model = '星期'):\n",
    "    '''\n",
    "    df : DataFrame格式数据\n",
    "    \n",
    "    model : df的列名，默认为“星期”\n",
    "    '''\n",
    "    week = []\n",
    "\n",
    "    for w in df[model]:\n",
    "        if w == '星期一' or w == 'Monday':\n",
    "            week.append(1)\n",
    "        elif w == '星期二' or w == 'Tuesday':\n",
    "            week.append(2)\n",
    "        elif w == '星期三' or w == 'Wednesday':\n",
    "            week.append(3)\n",
    "        elif w == '星期四' or w == 'Thursday':\n",
    "            week.append(4)\n",
    "        elif w == '星期五' or w == 'Friday':\n",
    "            week.append(5)\n",
    "        elif w == '星期六' or w == 'Saturday':\n",
    "            week.append(6)\n",
    "        else:\n",
    "            week.append(7)\n",
    "            \n",
    "    if model == '星期':\n",
    "        df['星期'] = week\n",
    "        return df\n",
    "    else:\n",
    "        return week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dfb491c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T17:07:18.307049900Z",
     "start_time": "2023-07-04T17:07:18.276049600Z"
    }
   },
   "outputs": [],
   "source": [
    "#将特殊天象数值化，若为空则为0，否则为1\n",
    "def weather2num(df):\n",
    "\t'''\n",
    "    df : DataFrame格式数据\n",
    "    '''\n",
    "\tw_list = []\n",
    "\tweather = df['特殊天象'].values\n",
    "\n",
    "\tfor w in weather:\n",
    "\t\tif str(w) == 'nan':\n",
    "\t\t\tw_list.append(0)\n",
    "\t\telse:\n",
    "\t\t\tw_list.append(1)\n",
    "\tdf['特殊天象'] = w_list\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44f1ef93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T17:07:18.307049900Z",
     "start_time": "2023-07-04T17:07:18.293049900Z"
    }
   },
   "outputs": [],
   "source": [
    "#增添节假日特征\n",
    "def add_holiday(df):\n",
    "\t'''\n",
    "    df : DataFrame格式数据\n",
    "    '''\n",
    "\tholiday = []\n",
    "\n",
    "\tfor date in df['交易日期']:\n",
    "\t\tdate = datetime.strptime(date, \"%Y/%m/%d\").date()\n",
    "\t\tif is_holiday(date):\n",
    "\t\t\tholiday.append(1)\n",
    "\t\telse:\n",
    "\t\t\tholiday.append(0)\n",
    "\n",
    "\tdf['节假日'] = holiday\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e06be3b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T17:07:18.322049200Z",
     "start_time": "2023-07-04T17:07:18.307049900Z"
    }
   },
   "outputs": [],
   "source": [
    "#增添时间戳特征\n",
    "def add_timestamp(df):\n",
    "\t'''\n",
    "    df : DataFrame格式数据\n",
    "    '''\n",
    "\tdf['时间戳'] = df['交易日期'] + ' ' + df['交易时间']\n",
    "\tdf['时间戳'] = df['时间戳'].apply(lambda x: time.mktime(time.strptime(x, '%Y/%m/%d %H:%M')))\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40055c23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T17:07:18.350052900Z",
     "start_time": "2023-07-04T17:07:18.325048800Z"
    }
   },
   "outputs": [],
   "source": [
    "#将原数据与天气数据结合起来\n",
    "def combine_climate(df, climate):\n",
    "\t'''\n",
    "    df : DataFrame格式数据\n",
    "\n",
    "    climate : DataFrame格式数据，包含天气信息\n",
    "    '''\n",
    "\t#将不足五位的天气数据用0补足，如7:00 -> 07:00\n",
    "\tclimate['时间'] = climate['时间'].str.zfill(5)\n",
    "\n",
    "\tdf['日期小时'] = df['交易日期'] + ' ' + df['时间'].str[:2]\n",
    "\tclimate['日期小时'] = climate['date'] + ' ' + climate['时间'].str[:2]\n",
    "\n",
    "\tmerged_df = pd.merge(df, climate, on='日期小时')\n",
    "\tmerged_df = merged_df.drop(['学工号', '姓名', '日期小时', 'date', '时间_x', '时间_y', '重要天象'], axis=1)\n",
    "\treturn merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4c4853a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T17:07:18.354049400Z",
     "start_time": "2023-07-04T17:07:18.343050600Z"
    }
   },
   "outputs": [],
   "source": [
    "#筛选合格的样本，如去除消费值过低（可能是买水等因素）的数据\n",
    "def select_data(df):\n",
    "\t'''\n",
    "    df : DataFrame格式数据\n",
    "\n",
    "    '''\n",
    "\t# 创建一个时间对象表示 10:00，用于区分上午和其他时段（早餐消费可能偏低）\n",
    "\tthreshold_time = pd.to_datetime('10:00', format='%H:%M')\n",
    "\n",
    "\t# 创建一个空的 DataFrame 用于存储筛选后的数据\n",
    "\tfiltered_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "\t# 迭代 DataFrame 行\n",
    "\tfor index, row in df.iterrows():\n",
    "\t\tif float(row['交易额']) <= 5 and pd.to_datetime(row['交易时间'], format='%H:%M') > threshold_time:\n",
    "\t\t\t# 跳过满足条件的行\n",
    "\t\t\tcontinue\n",
    "\t\telif float(row['交易额']) <= 2 and pd.to_datetime(row['交易时间'], format='%H:%M') < threshold_time:\n",
    "\t\t\t# 跳过满足条件的行\n",
    "\t\t\tcontinue\n",
    "\t\telse:\n",
    "\t\t\t# 将不满足条件的行添加到 filtered_df\n",
    "\t\t\tfiltered_df = pd.concat([filtered_df, row.to_frame().T], ignore_index=True)\n",
    "\treturn filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b3abe35",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# 根据课表信息生成个人数据库\n",
    "def creat_database(file_path):\n",
    "    original_personal_class1 = load_data(file_path,'transform_2022秋_lai.csv')\n",
    "    original_personal_class2 = load_data(file_path,'transform_2022夏_lai.csv')\n",
    "    original_personal_class3 = load_data(file_path,'transform_2023春_lai.csv')\n",
    "    original_personal_class=pd.concat([original_personal_class1,original_personal_class2],copy=True)\n",
    "    original_personal_class=pd.concat([original_personal_class,original_personal_class3],copy=True)\n",
    "    original_personal_class['Start Date'] = pd.to_datetime(\n",
    "        original_personal_class['Start Date'])\n",
    "    original_personal_class['Start Date'] = original_personal_class['Start Date'].dt.strftime(\n",
    "        '%Y/%m/%d')\n",
    "    original_personal_class['End Date'] = pd.to_datetime(\n",
    "        original_personal_class['End Date'])\n",
    "    original_personal_class['End Date'] = original_personal_class['End Date'].dt.strftime(\n",
    "        '%Y/%m/%d')\n",
    "    original_personal_class['Weekday'] = week2num(original_personal_class, model = 'Weekday')\n",
    "    courseType = ['Morning', 'Afternoon', 'Evening']\n",
    "    dataList = pd.date_range(\n",
    "        start='20220713', end='20230616').strftime('%Y/%m/%d').tolist()\n",
    "    personal_class = pd.DataFrame(0, index=courseType, columns=dataList)\n",
    "\n",
    "    for index, row in original_personal_class.iterrows():\n",
    "        column = pd.date_range(\n",
    "        start=row['Start Date'], end=row['End Date'], freq='W-MON')\n",
    "        \n",
    "        if row['Start Time'] == '08:00':\n",
    "            personal_class.loc['Morning',\n",
    "                               df.columns.isin(column)] = 1\n",
    "        elif row['End Time'] == '11:45':\n",
    "            personal_class.loc['Afternoon',\n",
    "                               df.columns.isin(column)] = 1\n",
    "        elif row['End Time'] == '17:30':\n",
    "            personal_class.loc['Evening',\n",
    "                               df.columns.isin(column)] = 1\n",
    "\n",
    "    return personal_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3179872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 判断当前交易行为与课程间的关系\n",
    "def combine_class(df, personal_class):\n",
    "    # 类似one-hot encode，采用二进制表示法，每一位表示一个餐点前有没有课\n",
    "    temp=df\n",
    "    temp['交易日期'] = pd.to_datetime(temp['交易日期'])\n",
    "    temp['交易日期'] = temp['交易日期'].dt.strftime('%Y/%m/%d')\n",
    "    list_1 = []\n",
    "    list_2 = []\n",
    "    list_3 = []\n",
    "    for index, row in temp.iterrows():\n",
    "        list_1.append(personal_class[row['交易日期']]['Morning'])\n",
    "        list_2.append(personal_class[row['交易日期']]['Afternoon'])\n",
    "        list_3.append(personal_class[row['交易日期']]['Evening'])\n",
    "    temp['8点上课']=list_1\n",
    "    temp['午饭有课']=list_2\n",
    "    temp['晚饭有课']=list_3\n",
    "    return temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf99a067",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T17:07:18.384032100Z",
     "start_time": "2023-07-04T17:07:18.355049100Z"
    }
   },
   "outputs": [],
   "source": [
    "#保存数据为csv文件\n",
    "def save_data(df, file_path, file_name):\n",
    "\t'''\n",
    "    df : DataFrame格式数据\n",
    "\n",
    "    file_path : 文件路径名，即Data或temp\n",
    "\n",
    "    file_name : 文件名，如：lai.csv\n",
    "    '''\n",
    "\n",
    "\tdf.to_csv('../' + file_path + '/' + file_name, sep=',', encoding='gbk', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "837b588b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T17:07:57.518416500Z",
     "start_time": "2023-07-04T17:07:57.007229100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2022-08-22'], dtype='datetime64[ns]', freq='W-MON')\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Boolean index has wrong length: 13 instead of 339",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m df \u001b[38;5;241m=\u001b[39m weather2num(df)\n\u001b[0;32m     18\u001b[0m df \u001b[38;5;241m=\u001b[39m select_data(df)\n\u001b[1;32m---> 19\u001b[0m db_c\u001b[38;5;241m=\u001b[39m\u001b[43mcreat_database\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtemp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m df \u001b[38;5;241m=\u001b[39m combine_class(df,db_c)\n\u001b[0;32m     21\u001b[0m df\n",
      "Cell \u001b[1;32mIn[29], line 27\u001b[0m, in \u001b[0;36mcreat_database\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(column)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStart Time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m08:00\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 27\u001b[0m     personal_class\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMorning\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     28\u001b[0m                        df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39misin(column)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnd Time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m11:45\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     30\u001b[0m     personal_class\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAfternoon\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     31\u001b[0m                        df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39misin(column)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\pyg\\lib\\site-packages\\pandas\\core\\indexing.py:845\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    844\u001b[0m     key \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m--> 845\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_setitem_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    848\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\pyg\\lib\\site-packages\\pandas\\core\\indexing.py:710\u001b[0m, in \u001b[0;36m_LocationIndexer._get_setitem_indexer\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[0;32m    709\u001b[0m         \u001b[38;5;66;03m# suppress \"Too many indexers\"\u001b[39;00m\n\u001b[1;32m--> 710\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mrange\u001b[39m):\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;66;03m# GH#45479 test_loc_setitem_range_key\u001b[39;00m\n\u001b[0;32m    714\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\pyg\\lib\\site-packages\\pandas\\core\\indexing.py:927\u001b[0m, in \u001b[0;36m_LocationIndexer._convert_tuple\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convert_tuple\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m:\n\u001b[0;32m    925\u001b[0m     \u001b[38;5;66;03m# Note: we assume _tupleize_axis_indexer has been called, if necessary.\u001b[39;00m\n\u001b[0;32m    926\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key_length(key)\n\u001b[1;32m--> 927\u001b[0m     keyidx \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_to_indexer(k, axis\u001b[38;5;241m=\u001b[39mi) \u001b[38;5;28;01mfor\u001b[39;00m i, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(key)]\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(keyidx)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\pyg\\lib\\site-packages\\pandas\\core\\indexing.py:927\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convert_tuple\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m:\n\u001b[0;32m    925\u001b[0m     \u001b[38;5;66;03m# Note: we assume _tupleize_axis_indexer has been called, if necessary.\u001b[39;00m\n\u001b[0;32m    926\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key_length(key)\n\u001b[1;32m--> 927\u001b[0m     keyidx \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_to_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(key)]\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(keyidx)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\pyg\\lib\\site-packages\\pandas\\core\\indexing.py:1423\u001b[0m, in \u001b[0;36m_LocIndexer._convert_to_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1420\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 1423\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_bool_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m key\n\u001b[0;32m   1425\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\pyg\\lib\\site-packages\\pandas\\core\\indexing.py:2525\u001b[0m, in \u001b[0;36mcheck_bool_indexer\u001b[1;34m(index, key)\u001b[0m\n\u001b[0;32m   2521\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_array_like(result):\n\u001b[0;32m   2522\u001b[0m     \u001b[38;5;66;03m# GH 33924\u001b[39;00m\n\u001b[0;32m   2523\u001b[0m     \u001b[38;5;66;03m# key may contain nan elements, check_array_indexer needs bool array\u001b[39;00m\n\u001b[0;32m   2524\u001b[0m     result \u001b[38;5;241m=\u001b[39m pd_array(result, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m-> 2525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcheck_array_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\pyg\\lib\\site-packages\\pandas\\core\\indexers\\utils.py:541\u001b[0m, in \u001b[0;36mcheck_array_indexer\u001b[1;34m(array, indexer)\u001b[0m\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;66;03m# GH26658\u001b[39;00m\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(indexer) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(array):\n\u001b[1;32m--> 541\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[0;32m    542\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBoolean index has wrong length: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    543\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(indexer)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(array)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    544\u001b[0m         )\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_integer_dtype(dtype):\n\u001b[0;32m    546\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mIndexError\u001b[0m: Boolean index has wrong length: 13 instead of 339"
     ]
    }
   ],
   "source": [
    "#通过更改文件名，处理不同组数据\n",
    "df = load_data('Data', 'lai.csv')\n",
    "climate = load_data('Data', 'climate.csv')\n",
    "\n",
    "abnormal_merchant = np.array(['淘乐学苑水果', '学苑食堂霞姐饮品店', '中央红小月亮门店5', '中央红小月亮门店2' \\\n",
    "\t\t\t\t\t\t\t\t , '中央红小月亮门店4', '中央红小月亮门店6', '中央红小月亮门店3', '中央红小月亮正心楼' \\\n",
    "\t\t\t\t\t\t\t\t , '中央红-水果', '哈尔滨市南岗区淘乐水果捞店', '中央红小月亮门店1', '中央红-药店' \\\n",
    "\t\t\t\t\t\t\t\t , '深澜网费对接', '中央红-辣货', '紫丁香餐吧酒水（聚鑫食品）', '回味斋一餐厅酒水组' \\\n",
    "\t\t\t\t\t\t\t\t , '美芝林快客', '灌制间'])\n",
    "df = cut_data(df, '商户名称', 590, abnormal_merchant)\n",
    "df = merge_data(df)\n",
    "df = time2int(df)\n",
    "df = add_holiday(df)\n",
    "df = combine_climate(df, climate)\n",
    "df = add_timestamp(df)\n",
    "df = week2num(df)\n",
    "df = weather2num(df)\n",
    "df = select_data(df)\n",
    "db_c=creat_database('temp')\n",
    "df = combine_class(df,db_c)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effb3972",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T17:08:03.246908Z",
     "start_time": "2023-07-04T17:08:03.226861400Z"
    }
   },
   "outputs": [],
   "source": [
    "#保存到temp目录下\n",
    "save_data(df, 'temp', '赖（final）.csv')\n",
    "save_data(db_c, 'temp', 'db_c_lai.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914eff4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "de6198b06f57e1390ad1d60a44807334cc05a1e9176d785a247f3558ce42b891"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
